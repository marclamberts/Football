import re
import json
import pandas as pd
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

def get_html_from_url(url):
    """
    Uses Selenium to open a URL, wait for the JavaScript to load the content,
    and returns the page's HTML source.
    """
    service = ChromeService(ChromeDriverManager().install())
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

    driver = None
    try:
        print(f"Setting up ChromeDriver...")
        driver = webdriver.Chrome(service=service, options=options)
        
        print(f"Fetching URL: {url}...")
        driver.get(url)
        
        WebDriverWait(driver, 30).until(
            EC.presence_of_element_located((By.ID, "court"))
        )
        
        print("Page and shot chart content loaded successfully. Extracting HTML...")
        html_content = driver.page_source
        return html_content
        
    except TimeoutException:
        print("Error: Timed out waiting for the page content to load.")
        print("The website might be slow, or the element with id='court' was not found.")
        return None
    except Exception as e:
        print(f"An error occurred during web scraping: {e}")
        return None
    finally:
        if driver:
            driver.quit()
            print("Browser closed.")

def parse_shot_data_from_html(html_content):
    """
    Parses HTML content to find and extract data from 'addShot' JavaScript function calls.
    """
    shot_pattern = re.compile(
        r"addShot\("
        r"([^,]+),"      # Group 1: x_coordinate
        r"\s*([^,]+),"   # Group 2: y_coordinate
        r"\s*([^,]+),"   # Group 3: team_id
        r"\s*([^,]+),"   # Group 4: made (boolean: true/false)
        r"\s*([^,]+),"   # Group 5: play_id
        r"\s*'([^']*)'," # Group 6: play_description
        r"\s*'([^']*)'," # Group 7: CSS classes
        r"\s*([^)]+)"    # Group 8: show_highlight (boolean)
        r"\);"
    )
    
    matches = shot_pattern.findall(html_content)
    
    shot_data = []
    for match in matches:
        shot_info = {
            "x_coordinate": float(match[0].strip()),
            "y_coordinate": float(match[1].strip()),
            "team_id": int(match[2].strip()),
            "made_shot": match[3].strip().lower() == 'true',
            "play_id": int(match[4].strip()),
            "description": match[5].strip(),
            "classes": match[6].strip(),
            "show_highlight": match[7].strip().lower() == 'true'
        }
        shot_data.append(shot_info)
        
    return shot_data

def save_to_excel(data, filename="ncaa_shot_data.xlsx"):
    """
    Saves a list of dictionaries to an Excel file.
    """
    if not data:
        print("No data to save to Excel.")
        return
        
    df = pd.DataFrame(data)
    
    try:
        df.to_excel(filename, index=False, engine='openpyxl')
        print(f"Successfully saved data to {filename}")
    except Exception as e:
        print(f"Error saving to Excel file: {e}")

def save_to_json(data, filename="ncaa_shot_data.json"):
    """
    Saves a list of dictionaries to a JSON file.
    """
    if not data:
        print("No data to save to JSON.")
        return
        
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            # The 'indent=2' argument makes the JSON file human-readable
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"Successfully saved data to {filename}")
    except Exception as e:
        print(f"Error saving to JSON file: {e}")

# --- Main part of the script ---
if __name__ == '__main__':
    #  <--- You can change the URL to any other game's box score ---
    url_to_scrape = "https://stats.ncaa.org/contests/6387673/box_score"
    
    # 1. Fetch the dynamic HTML from the URL
    html_source = get_html_from_url(url_to_scrape)

    if html_source:
        # 2. Parse the raw shot data from the HTML
        raw_shot_data = parse_shot_data_from_html(html_source)
        
        if raw_shot_data:
            # 3. Save the extracted data to both Excel and JSON files
            output_basename = "/Users/user/NCAA Shots/ncaa_game_shots" # You can change this file name
            save_to_excel(raw_shot_data, filename=f"{output_basename}.xlsx")
            save_to_json(raw_shot_data, filename=f"{output_basename}.json")
        else:
            print("Could not find any shot data in the page source.")
    else:
        print("Failed to retrieve HTML content. Cannot proceed.")
